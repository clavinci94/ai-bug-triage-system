# ðŸ¤– AI Bug Triage System

Dieses Projekt ist ein kleiner Prototyp, den ich gebaut habe, um zu zeigen, wie man mit **FastAPI** und etwas **Machine Learning** automatisch Software-Issues klassifizieren kann.  
Die Idee ist simpel: neue Tickets (z. B. von GitHub) kommen rein, und ein Modell schlÃ¤gt vor, ob es sich um einen Bug, ein Feature, ein Dokumentationsproblem oder eine Verbesserung handelt.  
So spart man Zeit beim manuellen Einsortieren und hat eine einheitlichere Struktur.

---

## Warum â€žBug Triageâ€œ?

Wer schon mal an einem Open-Source-Projekt oder in einem Entwicklungsteam gearbeitet hat, kennt das Problem:  
Es kommen jede Menge Issues rein â€“ manche sind echte Bugs, manche nur VorschlÃ¤ge, andere wieder Dokumentationsfehler.  
Das manuell zu sortieren ist mÃ¼hsam und kostet Zeit.  

Mein Ziel war es, diesen Prozess **teilweise zu automatisieren**:  
- Neue Issues importieren (z. B. direkt von GitHub).  
- Automatisch eine Kategorie vorschlagen.  
- Das Modell kann immer wieder neu trainiert werden, sobald es mehr Daten gibt.  

---

## Features

- **/health** â†’ einfacher Check, ob die API lÃ¤uft  
- **/issues/import** â†’ Issues aus einem GitHub-Repo holen (z. B. `tiangolo/fastapi`)  
- **/issues/classify** â†’ neues Issue klassifizieren lassen  
- **/issues/classify?save=true** â†’ das Issue gleichzeitig ins Dataset aufnehmen  
- **/issues/dataset** â†’ aktuellen Datensatz ansehen (`issues.csv`)  
- **/issues/retrain** â†’ Modell neu trainieren  

Die API ist mit Swagger dokumentiert und kann direkt im Browser unter `/docs` ausprobiert werden.

---

## Projektstruktur

```text
ai-bug-triage-system/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ main.py            # Einstiegspunkt (FastAPI App)
â”‚       â”œâ”€â”€ config.py          # Einstellungen (env Variablen)
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ schemas.py     # Pydantic Schemas
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â””â”€â”€ issues.py      # API Endpunkte
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ github.py      # Import von GitHub Issues
â”‚           â””â”€â”€ classifier.py  # Klassifikations-Logik (ML)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ issues.csv             # Trainingsdaten
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

- Voraussetzung: Python 3.10+  
- GitHub Token (falls private Repos importiert werden sollen)

## Setup
```
# Repository klonen
git clone <REPO_URL>
cd ai-bug-triage-system

# Virtuelle Umgebung erstellen & aktivieren
python -m venv .venv
source .venv/bin/activate   # macOS/Linux
# .venv\Scripts\activate    # Windows

# Dependencies installieren
pip install -r requirements.txt
```

## .env Datei
Falls ein privates GitHub Repo genutzt werden soll:
GITHUB_TOKEN=ghp_abc123meinToken
Starten des Servers:
python -m uvicorn backend.core.main:app --reload
Dann im Browser Ã¶ffnen:
ðŸ‘‰ http://127.0.0.1:8000/docs

## Starten
python -m uvicorn backend.core.main:app --reload

Die API ist dann erreichbar unter:
http://127.0.0.1:8000/docs

## Beispiel-Requests

### Alle Anfragen an die API folgen der gleichen Struktur:
```
{
    "title": "Kurze Zusammenfassung des Issues",
    "body": "Detaillierte Beschreibung des Issues."
}
```

### Klassifikation: Bug
```

  {
    "title": "New crash when exporting PDF",
    "body": "The app crashes immediately when exporting PDF."
  }
```

### Beispiel Antwort
```
{
  "category": "bug",
  "confidence": 0.91,
  "rationale": "ML-NaiveBayes auf Mini-Dataset"
}
```
### Beispiel 2

```
{
    "title": "UI freezes on logout",
    "body": "The application becomes unresponsive for 10 seconds after logging out."
}
```
### Beispiel Antwort
```
{
  "category": "bug",
  "confidence": 0.5017993320213663,
  "rationale": "ML-NaiveBayes auf issues.csv"
}
```
### Beispiel Feature
```
{
    "title": "Add dark mode",
    "body": "It would be great to have a dark mode for the UI."
}
```

## Machine Learning
Aktuell steckt hinter der Klassifizierung ein recht einfaches Modell:
Texte werden mit TF-IDF in Vektoren umgewandelt
Klassifikation mit einem Naive Bayes Modell
Trainingsdaten liegen in issues.csv
Das SchÃ¶ne: wenn neue Daten reinkommen, kann das Modell direkt per API neu trainiert werden.
SpÃ¤ter kÃ¶nnte man hier stÃ¤rkere Modelle einsetzen (z. B. BERT oder Sentence Transformers), aber fÃ¼r den ersten Prototyp reicht das vÃ¶llig.

## Fazit
Das Projekt hat mir geholfen, Backend-Entwicklung und Machine Learning in einem praktischen Kontext zu verbinden.
Besonders spannend war fÃ¼r mich der Workflow von Datenimport â†’ Modelltraining â†’ API-Endpunkt â†’ Dokumentation in Swagger.
Es ist ein Lernprojekt, aber mit echter Relevanz fÃ¼r den Alltag von Entwicklern, die groÃŸe Open-Source-Repos managen.







